{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline \n\nimport cv2\n\nimport os\nimport tensorflow\ntensorflow.__version__\n\nimport os, shutil # sorting files\n\nimport matplotlib.pyplot as plt # data visualization\n\nimport torch\nimport kornia\nimport cv2\nfrom keras.preprocessing.image import array_to_img\nfrom keras.preprocessing.image import save_img","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-18T01:59:09.814762Z","iopub.execute_input":"2022-04-18T01:59:09.815131Z","iopub.status.idle":"2022-04-18T01:59:16.274287Z","shell.execute_reply.started":"2022-04-18T01:59:09.815044Z","shell.execute_reply":"2022-04-18T01:59:16.273538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/happy-whale-and-dolphin/train.csv')\nspecies = df['species'].tolist()\nids = df['individual_id'].tolist()\nimgList = df['image'].tolist()\nos.makedirs('../working/train_species_list', exist_ok=False)\n\npath = '../input/whale2-cropped-dataset/cropped_train_images/cropped_train_images/'\nprint(len(species))\nfor x in range(round(len(species))):\n    \n    # read the image with OpenCV\n    img = cv2.imread(path + str(imgList[x]))\n    #flip the image horizontally and make a copy\n    flipped = cv2.flip(img, 1)\n    # convert to torch tensor\n    data = kornia.image_to_tensor(img, keepdim=False)\n    data = data.float() / 255.\n    # create the operator\n    sharpen = kornia.filters.UnsharpMask((9,9), (2.5,2.5))\n    sharpened_tensor = sharpen(data)\n    # Convert back to image\n    sharpened_image = kornia.utils.tensor_to_image(sharpened_tensor) \n    sharpened_image = array_to_img(sharpened_image)\n    flipped = array_to_img(flipped)\n        \n    path3 = '../working/train_species_list/' + ids[x]\n    if not (os.path.isdir(path3)):\n        os.makedirs(path3, exist_ok=False)\n    shutil.copy(path + str(imgList[x]), path3)\n    save_img(path3 + \"/\" + imgList[x] + \"_flipped.jpg\", flipped)\n    save_img(path3 + \"/\" + imgList[x] + \"_sharpened.jpg\", sharpened_image)\n    if(x == 100):\n        print(x)\n    elif(x%1000 == 0):\n        print(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fixed for Cats & Dogs color images\nCHANNELS = 3\n\nIMAGE_RESIZE = 256\nRESNET50_POOLING_AVERAGE = 'avg'\nDENSE_LAYER_ACTIVATION = 'softmax'\n\nOBJECTIVE_FUNCTION = 'categorical_crossentropy'\n\n# Common accuracy metric for all outputs, but can use different metrics for different output\nLOSS_METRICS = ['accuracy']\n\n# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n# Training images processed in each step would be no.-of-train-images / STEPS_PER_EPOCH_TRAINING\nSTEPS_PER_EPOCH_TRAINING = 100\n\n# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n# NOTE that these BATCH* are for Keras ImageDataGenerator batching to fill epoch step input\nBATCH_SIZE_TRAINING = 100\n\n# Using 1 to easily manage mapping between test_generator & prediction for submission preparation\nBATCH_SIZE_TESTING = 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense\n\n### \n### Below systax is available with TensorFlow 1.11 onwards but this upgrade is not available for Kaggle kernel yet\n###\n#import tensorflow as tf\n#print(tf.__version__)\n#import tensorflow as tf\n#from tf.keras.applications import ResNet50\n#from tf.keras.models import Sequential","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Still not talking about our train/test data or any pre-processing.\n\nmodel = Sequential()\n\n# 1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n# NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\nmodel.add(tensorflow.keras.applications.ResNet152(include_top = False, pooling = RESNET50_POOLING_AVERAGE, weights = 'imagenet'))\n\n# 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\nmodel.add(Dense(8192, activation = 'relu'))\nmodel.add(Dense(15587, activation = DENSE_LAYER_ACTIVATION))\n\n# Say not to train first layer (ResNet) model as it is already trained\nmodel.layers[0].trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimage_size = IMAGE_RESIZE\n\n# preprocessing_function is applied on each image but only after re-sizing & augmentation (resize => augment => pre-process)\n# Each of the keras.application.resnet* preprocess_input MOSTLY mean BATCH NORMALIZATION (applied on each batch) stabilize the inputs to nonlinear activation functions\n# Batch Normalization helps in faster convergence\ndata_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n\n# flow_From_directory generates batches of augmented data (where augmentation can be color conversion, etc)\n# Both train & valid folders must have NUM_CLASSES sub-folders\ntrain_generator = data_generator.flow_from_directory(\n        '../working/train_species_list',\n        target_size=(image_size, image_size),\n        batch_size=BATCH_SIZE_TRAINING,\n        class_mode='categorical',\n        shuffle = True)\n\nvalid_generator = data_generator.flow_from_directory(\n        '../input/happywhalesortedbyindividual/train_species_list',\n        target_size=(image_size, image_size),\n        class_mode='categorical',\n        batch_size=100,\n        shuffle = True)\n\nprint(train_generator.samples)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Max number of steps that these generator will have opportunity to process their source content\n# len(train_generator) should be 'no. of available train images / BATCH_SIZE_TRAINING'\n# len(valid_generator) should be 'no. of available train images / BATCH_SIZE_VALIDATION'\n(BATCH_SIZE_TRAINING, len(train_generator),)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nloss = tensorflow.keras.losses.CategoricalCrossentropy()\n\nmodel.compile(optimizer='sgd',\n              loss=loss,\n              metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit_history = model.fit_generator(\n        train_generator,\n        steps_per_epoch=len(train_generator)//BATCH_SIZE_TRAINING,\n        epochs = 128,\n        shuffle = True,\n        validation_data=valid_generator,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(fit_history.history.keys())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_model('happy-whale-resnet-152.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}